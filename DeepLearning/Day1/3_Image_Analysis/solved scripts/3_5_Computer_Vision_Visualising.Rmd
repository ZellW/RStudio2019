---
title: "Computer Vision"
subtitle: "Visualizing Cats and Dogs"
author: "Rick Scavetta"
output:
  html_document:
  fig_caption: true
  toc: true
  toc_float:
    collapsed: false
    smooth_scroll: false
  toc_depth: 2
---

# {.tabset .tabset-fade .tabset-pills}

## Learning Goals & Functions

### Learning Goals

Look at what actually happens to an image in a convnet and what filters are used in a trained model.

### Functions in this session:

| Function           | Description                                |
|:-------------------|:-------------------------------------------|
| `image_load()`     | Import and resize an image.                |
| `image_to_array()` | Convert image to an array.                 |
| `array_reshape()`  | Reshape an array for use with tensorflow.  |
| `as.raster()`      | Convert a matrix to a raster for plotting. |
| `x$output`         | The output layer of a model `x`.           |

## Data sources

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, eval = FALSE)

# Initialize package
library(keras)

# define the directories:
source("dir_cat_dog.R")
```

## Pre-trained Small

```{r getModel}

model_conv <- load_model_hdf5("cats_and_dogs_small_convnet.h5")
model_conv

```

## View

```{r getIMG}

img_path <- "~/data/cats_and_dogs/test/cats/cat.1700.jpg"
img <- image_load(img_path, target_size = c(150, 150))


img_tensor <- image_to_array(img)
img_tensor <- array_reshape(img_tensor, c(1, 150, 150, 3))
img_tensor <- img_tensor / 255

# Preprocesses the image into a 4D tensor
dim(img_tensor)

```

## Plot Image

```{r vizIMG}

plot(as.raster(img_tensor[1,,,]))

```

Instantiating a model from an input tensor and a list of output tensors

```{r act0}

layer_outputs <- lapply(model_conv$layers[1:8], function(layer) layer$output)
activation_model <- keras_model(inputs = model_conv$input, outputs = layer_outputs)

```

Running the model in predict mode

```{r act1}

activations <- activation_model %>% predict(img_tensor)

```

this is the activation of the first convolution layer for the cat image input:

```{r act2}

first_layer_activation <- activations[[1]]
dim(first_layer_activation)

```

## Plot Channels

Function to plot a channel

```{r vizFUN}

plot_channel <- function(channel) {
  rotate <- function(x) t(apply(x, 2, rev))
  image(rotate(channel), axes = FALSE, asp = 1,
        col = terrain.colors(12))
}

```

Plotting the second channel

```{r viz2}

plot_channel(first_layer_activation[1,,,2])

```

Visualizing the seventh channel

```{r viz7}

plot_channel(first_layer_activation[1,,,7])

```

## Visualizing Covnnet Filters

We can visualize every channel in every intermediate activation. All the following images have been saved to the working directory.

```{r vizAll, eval = FALSE}

image_size <- 58
images_per_row <- 16

for (i in 1:8) {
  layer_activation <- activations[[i]]
  layer_name <- model_conv$layers[[i]]$name
  n_features <- dim(layer_activation)[[4]]
  n_cols <- n_features %/% images_per_row
  png(paste0("cat_activations_", i, "_", layer_name, ".png"),
      width = image_size * images_per_row,
      height = image_size * n_cols)
  op <- par(mfrow = c(n_cols, images_per_row), mai = rep_len(0.02, 4))
  for (col in 0:(n_cols-1)) {
    for (row in 0:(images_per_row-1)) {
      channel_image <- layer_activation[1,,,(col*images_per_row) + row + 1]
      plot_channel(channel_image)
    }
  }
  par(op)
  dev.off() }

```

Here are some additional visualization functions from the _Deep Learning with R_ book that you can execute to visualize you filters. We won't go into detail in the workshop. All outputs are save in the working directory.

Defining the loss tensor for filter visualization (Listing 5.32)

```{r}

library(keras)

model <- application_vgg16(
  weights = "imagenet",
  include_top = FALSE
)

layer_name <- "block3_conv1"
filter_index <- 1
layer_output <- get_layer(model, layer_name)$output
loss <- k_mean(layer_output[,,,filter_index])

```

Obtaining the gradient of the loss with regard to the input (Listing 5.33)

The call to k_gradients returns an R list of tensors (of size 1 in this case). Hence, you keep only the first element—which is a tensor.

```{r}

# The call to k_gradients returns an R list of tensors (of size 1 in this case). Hence, you keep only the first element—which is a tensor.
grads <- k_gradients(loss, model$input)[[1]]

```

Gradient-normalization trick (Book Listing 5.34)

```{r}

# Add 1e-5 before dividing to avoid accidentally dividing by 0
grads <- grads / (k_sqrt(k_mean(k_square(grads))) + 1e-5)

```

Fetching output values given input values (Book Listing 5.35)

```{r}

iterate <- k_function(list(model$input), list(loss, grads))
c(loss_value, grads_value) %<-%
  iterate(list(array(0, dim = c(1, 150, 150, 3))))

```

Loss maximization via stochastic gradient descent (Book Listing 5.36 )

```{r}
# Starts from a gray image with some noise
input_img_data <- array(runif(150 * 150 * 3), dim = c(1, 150, 150, 3)) * 20 + 128

# Runs gradient ascent for 40 step
step <- 1
for (i in 1:40) { 
  # Computes the loss value and gradient value
  c(loss_value, grads_value) %<-% iterate(list(input_img_data))
  
  # Adjusts the input image in the direction that maximizes the loss
  input_img_data <- input_img_data + (grads_value * step)  
}

```

Utility function to convert a tensor into a valid image (Book Listing 5.37)

```{r}
deprocess_image <- function(x) {
  dms <- dim(x)
  
  # Normalizes the tensor: centers on 0., ensures that std is 0.1
  x <- x - mean(x)
  x <- x / (sd(x) + 1e-5)
  x <- x * 0.1
  
  # Clips to [0, 1]
  x <- x + 0.5
  x <- pmax(0, pmin(x, 1))
  
  # Returns with the original image dimensions
  array(x, dim = dms)
}
```

Function to generate filter visualizations

```{r}
generate_pattern <- function(layer_name, filter_index, size = 150) {
  
  # Builds a loss function that maximizes the activation of the nth filter of the layer under consideration
  layer_output <- model$get_layer(layer_name)$output
  loss <- k_mean(layer_output[,,,filter_index])
  
  # Computes the gradient of the input picture with regard to this loss
  grads <- k_gradients(loss, model$input)[[1]]
  
  # Normalization trick: normalizes the gradient
  grads <- grads / (k_sqrt(k_mean(k_square(grads))) + 1e-5)
  
  # Returns the loss and grads given the input picture
  iterate <- k_function(list(model$input), list(loss, grads))
  
  # Starts from a gray image with some noise
  input_img_data <-
    array(runif(size * size * 3), dim = c(1, size, size, 3)) * 20 + 128
  # Runs gradient ascent for 40 steps
  step <- 1
  for (i in 1:40) {
    c(loss_value, grads_value) %<-% iterate(list(input_img_data))
    input_img_data <- input_img_data + (grads_value * step)
  }
  
  img <- input_img_data[1,,,]
  deprocess_image(img)
}

```

Generating a grid of all filter response patterns in a layer (Book Listing 5.39)

```{r}
library(grid)
library(gridExtra)
dir.create("vgg_filters")
for (layer_name in c("block1_conv1", "block2_conv1",
                     "block3_conv1", "block4_conv1")) {
  size <- 140
  png(paste0("vgg_filters/", layer_name, ".png"),
      width = 8 * size, height = 8 * size)
  grobs <- list()
  for (i in 0:7) {
    for (j in 0:7) {
      pattern <- generate_pattern(layer_name, i + (j*8) + 1, size = size)
      grob <- rasterGrob(pattern,
                         width = unit(0.9, "npc"),
                         height = unit(0.9, "npc"))
      grobs[[length(grobs)+1]] <- grob
    } }
  grid.arrange(grobs = grobs, ncol = 8)
  dev.off()
}

```


