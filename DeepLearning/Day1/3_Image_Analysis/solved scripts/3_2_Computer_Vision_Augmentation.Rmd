---
title: "Computer Vision"
subtitle: "Image Augmentation"
author: "Rick Scavetta"
output:
  html_document:
  fig_caption: true
  toc: true
  toc_float:
    collapsed: false
    smooth_scroll: false
  toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, eval = FALSE)

# Initialize package
library(keras)
library(tidyverse)

# define the directories:
source("dir_cat_dog.R")
```

# {.tabset .tabset-fade .tabset-pills}

## Learning Goals & Functions

### Learning Goals

Learn how to apply image augmentation to avoid over-fitting.

### Functions in this session:

Here, we'll see arguments inside `image_data_generator()` 

| Argument              | Value       |
|:----------------------|:------------|
| `rescale`             | `1/255`     |
| `rotation_range`      | `40`        |
| `width_shift_range`   | `0.2`       |
| `height_shift_range`  | `0.2`       |
| `shear_range`         | `0.2`       |
| `zoom_range`          | `0.2`       |
| `horizontal_flip`     | `TRUE`      |
| `fill_mode`           | `"nearest"` |

Otherwise, the model and functions are as before.

## Data

```{r dataGet}

data.frame(Cats = c(length(list.files(train_cats_dir)),
                    length(list.files(validation_cats_dir)),
                    length(list.files(test_cats_dir))),
           Dogs = c(length(list.files(train_dogs_dir)),
                    length(list.files(validation_dogs_dir)),
                    length(list.files(test_dogs_dir))),
           row.names = c("Training", "Validation", "Test"))


```

## Define and compile model

Using dropout:

- Four sequential conv and max pooling layers
- Flatten layer
- Dropout (new)
- Densely-connected network
- Single binary output

```{r modelDefine}
model <- keras_model_sequential() %>%

  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu", input_shape = c(150, 150, 3)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_flatten() %>%
  
  layer_dropout(rate = 0.5) %>%
  
  layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4), 
  metrics = "accuracy"
)

summary(model)

```

## Data Augmentation

```{r dataGen0}
datagen <- image_data_generator(
  rescale = 1/255,
  rotation_range = 40,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  shear_range = 0.2,
  zoom_range = 0.2,
  horizontal_flip = TRUE,
  fill_mode = "nearest"
)
```

- Read in the image and resize it
- Converts to an array with shape (150, 150, 3)
- Reshapes it to (1, 150, 150, 3)
- Generates batches of randomly transformed images.

```{r augImages}

fnames <- list.files(train_cats_dir, full.names = TRUE)
img_path <- fnames[[3]]
img <- image_load(img_path, target_size = c(150, 150))
img_array <- image_to_array(img)
img_array <- array_reshape(img_array, c(1, 150, 150, 3))

augmentation_generator <- flow_images_from_data(
  img_array,
  generator = datagen,
  batch_size = 1
)

```

View augmented images

```{r viewImages}

op <- par(mfrow = c(2, 2), pty = "s", mar = c(1, 0, 1, 0))
for (i in 1:4) {
  batch <- generator_next(augmentation_generator)
  plot(as.raster(batch[1,,,]))
}
par(op)

```

Use augmented images:

```{r dataGen1}

datagen <- image_data_generator(
  rescale = 1/255, 
  rotation_range = 40, 
  width_shift_range = 0.2, 
  height_shift_range = 0.2, 
  shear_range = 0.2,
  zoom_range = 0.2,
  horizontal_flip = TRUE
)

```

Note that the validation data shouldn't be augmented!

```{r dataGen2}

train_generator <- flow_images_from_directory(
  train_dir,
  datagen,
  target_size = c(150, 150),
  batch_size = 32,
  class_mode = "binary"
)

validation_generator <- flow_images_from_directory(
  validation_dir,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 32,
  class_mode = "binary"
)

```

## Train

This will take a long time -- even on a GPU -- so I've saved the model and history after training. You can use that later on for assessing performance.

```{r modelTrain}

history <- model %>% fit_generator(
  train_generator,
  steps_per_epoch = 100,
  epochs = 100,
  validation_data = validation_generator,
  validation_steps = 50
)

```

Save model and history for later

```{r saveModel, eval = FALSE}

save(history, file = "history_augmentation.RData")

model %>% save_model_hdf5("cats_and_dogs_augmentation.h5")
```


View history

```{r historyView}
# load("history_augmentation.RData")
plot(history)
```

## Evaluation

```{r}

model_aug <- load_model_hdf5("cats_and_dogs_augmentation.h5")

# Test generator function:
test_datagen <- image_data_generator(rescale = 1/255)

test_generator <- flow_images_from_directory(
  test_dir,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary"
)

model_aug %>% evaluate_generator(test_generator, steps = 50)

```
