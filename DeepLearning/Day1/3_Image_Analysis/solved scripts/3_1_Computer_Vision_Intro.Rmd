---
title: "Computer Vision"
subtitle: "Intro to Convnets"
author: "Rick Scavetta"
output:
  html_document:
  fig_caption: true
  toc: true
  toc_float:
    collapsed: false
    smooth_scroll: false
  toc_depth: 2
---

```{r setup, include=FALSE}
setwd("~/GitHub/RStudio2019/DeepLearning/Day1/3_Image_Analysis/solved scripts")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, eval = FALSE)

# Initialize packages
library(keras)
library(tidyverse)

# define the directories:
#source("dir_cat_dog.R")

# define the directories:
#source("dir_cat_dog.R")# Data Directories for cat and dog pictures

# For local use:
# base_dir <- "~/data/cats_and_dogs"
base_dir <- "../../../../../LargeDataFiles/CatsDogs"

# For RStudio::Conf
#base_dir <- "/../../usr/share/class/cats_and_dogs"

# Train sets:
train_dir <- file.path(base_dir, "train", fsep = "/")
train_cat_dir <- file.path(train_dir, "cat", fsep = "/")
train_dog_dir <- file.path(train_dir, "dog", fsep = "/")

# Validation sets:
validation_dir <- file.path(base_dir, "validation", fsep = "/")
validation_cat_dir <- file.path(validation_dir, "cat", fsep = "/")
validation_dog_dir <- file.path(validation_dir, "dog", fsep = "/")

# Test sets:
test_dir <- file.path(base_dir, "test", fsep = "/")
test_cat_dir <- file.path(test_dir, "cat", fsep = "/")
test_dog_dir <- file.path(test_dir, "dog", fsep = "/")

#list.files("../../../../../LargeDataFiles/CatsDogs")

```

# {.tabset .tabset-fade .tabset-pills}

## Learning Goals & Functions

### Learning Goals

Understand how to set up and train a convolutional neural network (CNN) for computer vision.

### Functions in this session:

Functions in the `tfruns` package:

| Function                       | Use                                                                               |
|:-------------------------------|:----------------------------------------------------------------------------------|
| `layer_conv_2d()`              | Add a convolutional layer.                                                        |
| `layer_max_pooling_2d()`       | Add a 2d Max pooling layer.                                                       |
| `layer_flatten()`              | Add a flattening layer.                                                           |
| `optimizer_rmsprop()`          | Specify the optimizer function learning rate manually.                            |
| `image_data_generator()`       | Generator function for importing and scaling images.                              |
| `flow_images_from_directory()` | Sequentially read in all images from a directory using a generator function.      |
| `fit_generator()`              | Train a model using generator functions.                                          |
| `evaluate_generator()`         | Evaluate a convnet model that uses generator functions with a test set generator. |
 
## Data

### Examine data:

```{r strImagesPre}

data.frame(Cats = c(length(list.files(train_cat_dir)),
                    length(list.files(validation_cat_dir)),
                    length(list.files(test_cat_dir))),
           Dogs = c(length(list.files(train_dog_dir)),
                    length(list.files(validation_dog_dir)),
                    length(list.files(test_dog_dir))),
           row.names = c("Training", "Validation", "Test"))
```

## Define Network

- Four sequential conv and max pooling layers
- Flatten layer
- Densely-connected network
- Single binary output

```{r}

model <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu", input_shape = c(150, 150, 3)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_flatten() %>%
  
  layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

summary(model)

```

Compile the model:

```{r}
model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4),
  metrics = "accuracy"
)

```

## Read images from directories

Use `image_data_generator()`

```{r}

train_datagen <- image_data_generator(rescale = 1/255)
validation_datagen <- image_data_generator(rescale = 1/255)

train_generator <- flow_images_from_directory(
  train_dir,
  train_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary"
)

validation_generator <- flow_images_from_directory(
  validation_dir,
  validation_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary"
)
```

View batches

```{r}

batch <- generator_next(train_generator)
str(batch)

```

## Train

```{r}

history <- model %>% fit_generator(
  train_generator,
  steps_per_epoch = 100,
  epochs = 30,
  validation_data = validation_generator,
  validation_steps = 50
)

```

View history

```{r historyView}
plot(history)
```

## Save the model

```{r modelSave}
# model %>% save_model_hdf5("cats_and_dogs_small_convnet.h5")
```

## Evaluation

```{r}

model_conv <- load_model_hdf5("cats_and_dogs_small_convnet.h5")

# Test generator function:
test_datagen <- image_data_generator(rescale = 1/255)

test_generator <- flow_images_from_directory(
  test_dir,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary"
)

model_conv %>% evaluate_generator(test_generator, steps = 50)

```
